# ML

## References: 
![picture alt](http://scikit-learn.org/stable/_static/ml_map.png)

----

### Day 1: KNN ###
* Finding the distance between the test point to all train points, and choose the majority from K nearest neighbour.
* Distance fucntions explained (Euclidean, Manhattan, Minkowski and Hamming): https://www.saedsayad.com/k_nearest_neighbors.htm
* [Source code:] https://www.kaggle.com/vamshavardhanreddy/knn-implementation-using-pandas
	
### Day 2: 
Linear regression
* A linear classifier does classification decision based on the value of a linear combination of the characteristics.
* reference: https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/linear_classification.html
* Source code: https://www.kaggle.com/vamshavardhanreddy/linear-regression

Feature Selection
* We mainly use feature selection techinques to get insights about the features and their relative importance with the target variable.The idea is to keep most relevant but not redundant feature for predictive model that can yield optimal accuracy.
* source code: https://www.kaggle.com/vamshavardhanreddy/feature-selection	

### Day 3: 
Decision Trees
* Cost functions:
	* Regression : Mean squared error
	* Classification : GINI
* concept explanation: https://github.com/vamsha/100daysofML/blob/master/Decision_tree
* Source code: https://www.kaggle.com/vamshavardhanreddy/decision-tree-implementation-using-pandas

